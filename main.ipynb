{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# data feeding\n",
    "batch_size = 32\n",
    "\n",
    "# fft variables\n",
    "spec_feature_count = 128\n",
    "\n",
    "\n",
    "# lstm segments\n",
    "segment_length_secs = 5\n",
    "segment_length = librosa.time_to_frames(segment_length_secs)\n",
    "\n",
    "\n",
    "drum_notes = [35, 38, 42, 46, 41, 43, 45, 47, 48, 50, 49, 51]\n",
    "output_classes = len(drum_notes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pretty_midi\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from os.path import isfile\n",
    "import glob\n",
    "from multiprocessing import Process\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# TODO: data augmentation using audiomentations: https://github.com/iver56/audiomentations\n",
    "# TODO: pad data with zero_padding / silence\n",
    "\n",
    "class PlotLosses(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure()\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print('loss: ' + str(logs.get('loss')))\n",
    "        print(\"val_loss:\" + str(logs.get('val_loss')))\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.ylim(0, 0.1)\n",
    "        plt.yticks(np.arange(0.01, 0.1, 0.01))\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "# Maps notes into 12 drum classes (kick, snare, closed hihat, open hihat, 6x toms, crash cymbal, ride cymbal)\n",
    "gm_drum_map = {\n",
    "    # kicks\n",
    "    35: 35,\n",
    "    36: 35,\n",
    "    # snares\n",
    "    38: 38,\n",
    "    40: 38,\n",
    "    # hihats\n",
    "    42: 42,\n",
    "    44: 42,\n",
    "    # open hihat\n",
    "    46: 46,\n",
    "    # toms\n",
    "    41: 41,\n",
    "    43: 43,\n",
    "    45: 45,\n",
    "    47: 47,\n",
    "    48: 48,\n",
    "    50: 50,\n",
    "    # crash / splash cymbals\n",
    "    49: 49,\n",
    "    55: 49,\n",
    "    57: 49,\n",
    "    # ride cymbals\n",
    "    51: 51,\n",
    "    59: 51,\n",
    "}\n",
    "\n",
    "class_to_idx = {k: v for v, k in enumerate(drum_notes)}\n",
    "thread_count = 16\n",
    "high_pass_hz = 15000\n",
    "high_pass_ratio = 40\n",
    "\n",
    "def plot_labels(labels):\n",
    "    plt.yticks(range(12), [pretty_midi.note_number_to_drum_name(n) for n in drum_notes])\n",
    "    plt.imshow(labels, interpolation='nearest', aspect='auto')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "def samples_to_np(a):\n",
    "    return np.array(a.get_array_of_samples()).astype(np.float32) / 32767.0\n",
    "\n",
    "def process_file(data_file, callback):\n",
    "    label_file = data_file[:-4] + '.midi'\n",
    "    if not isfile(data_file) or not isfile(label_file):\n",
    "        return\n",
    "    audio, sr = librosa.load(data_file)\n",
    "    if np.isnan(audio).any():\n",
    "        raise Exception('found nan in transformed audio clip')\n",
    "    stft_features = librosa.power_to_db(librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=spec_feature_count, n_fft=2048, hop_length=512))\n",
    "    if np.isnan(stft_features).any():\n",
    "        raise Exception('found nan in stft')\n",
    "\n",
    "    # print(stft_features.shape)\n",
    "    # plt.figure(figsize=(20, 10))\n",
    "    # librosa.display.specshow(stft_features[:, :500])\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "\n",
    "    pm = pretty_midi.PrettyMIDI(label_file)\n",
    "    instrument = pm.instruments[0]\n",
    "    pitches = []\n",
    "    onsets = []\n",
    "\n",
    "    for i, note in enumerate(instrument.notes):\n",
    "        mapped_note = gm_drum_map.get(note.pitch, 0)\n",
    "        if mapped_note == 0:\n",
    "            continue\n",
    "        if note.velocity < 5:\n",
    "            continue\n",
    "        pitches.append(mapped_note)\n",
    "        onsets.append(note.start)\n",
    "\n",
    "    onset_frames = librosa.time_to_frames(onsets, sr=sr)\n",
    "    labels = np.zeros((output_classes, stft_features.shape[1]), dtype='int64')\n",
    "\n",
    "    for i in range(len(onsets)):\n",
    "        frame = onset_frames[i]\n",
    "        if frame >= labels.shape[1]:\n",
    "            continue\n",
    "        class_idx = class_to_idx.get(pitches[i])\n",
    "        labels[class_idx][frame] = 1\n",
    "        # Soft target vectors\n",
    "        if frame > 0:\n",
    "            labels[class_idx][frame - 1] = 0.5\n",
    "        if frame < labels.shape[1] - 1:\n",
    "            labels[class_idx][frame + 1] = 0.5 \n",
    "\n",
    "    segment_count = stft_features.shape[1] // segment_length\n",
    "    for i in range(segment_count):\n",
    "        stft_slice = stft_features[:, i * segment_length:(i + 1) * segment_length]\n",
    "\n",
    "        labels_slice = labels[:, i * segment_length:(i + 1) * segment_length]\n",
    "        if stft_slice.shape[1] != labels_slice.shape[1]:\n",
    "            raise Exception('mismatched total frame count between stft_features and labels')\n",
    "        callback(stft_slice, labels_slice)\n",
    "\n",
    "def _write_tfrecords_thread(tfrecord_path, data_files):\n",
    "    with tf.io.TFRecordWriter(tfrecord_path) as writer:\n",
    "        for i in range(len(data_files)):\n",
    "            def write_record(stft_slice, labels_slice):\n",
    "                feature = {\n",
    "                    'stft': tf.train.Feature(float_list=tf.train.FloatList(value=stft_slice.flatten())),\n",
    "                    'labels': tf.train.Feature(float_list=tf.train.FloatList(value=labels_slice.flatten())),\n",
    "                }\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "                writer.write(example.SerializeToString())\n",
    "\n",
    "            process_file(data_files[i], write_record)\n",
    "\n",
    "ENABLE_THREADING = True\n",
    "def write_tfrecords(data_files, tfrecord_path_prefix):\n",
    "    if not ENABLE_THREADING:\n",
    "        _write_tfrecords_thread(tfrecord_path_prefix + '.tfrecords', data_files)\n",
    "    else:\n",
    "        coord = tf.train.Coordinator()\n",
    "        processes = []\n",
    "        chunked_data_files = np.array_split(data_files, thread_count)\n",
    "        for thread_index in range(thread_count):\n",
    "            args = (tfrecord_path_prefix + str(thread_index) + '.tfrecords', chunked_data_files[thread_index])\n",
    "            p = Process(target=_write_tfrecords_thread, args=args)\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "        coord.join(processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Process all raw wav/midi files and extract features\n",
    "# import glob\n",
    "\n",
    "# train_files = glob.glob('/mnt/d/drums/train/**/*.wav', recursive=True)\n",
    "# validate_files = glob.glob('/mnt/d/drums/valid/**/*.wav', recursive=True)\n",
    "\n",
    "# print(f'Processing {len(train_files) + len(validate_files)} files')\n",
    "\n",
    "# # print(train_files)\n",
    "# write_tfrecords(train_files, '/mnt/d/drums/train')\n",
    "# write_tfrecords(validate_files, '/mnt/d/drums/validate')\n",
    "\n",
    "# print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features from Google cloud storage\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from google.cloud import storage\n",
    "\n",
    "TRAIN_TFRECORDS = []\n",
    "VALID_TFRECORDS = []\n",
    "\n",
    "client = storage.Client()\n",
    "for blob in client.list_blobs('drums-bucket'):\n",
    "    if blob.name.startswith('train'):\n",
    "        TRAIN_TFRECORDS.append(blob.name)\n",
    "    elif blob.name.startswith('validate'):\n",
    "        VALID_TFRECORDS.append(blob.name)\n",
    "\n",
    "TRAIN_TFRECORDS = [f'gs://drums-bucket/{f}' for f in TRAIN_TFRECORDS]\n",
    "VALID_TFRECORDS = [f'gs://drums-bucket/{f}' for f in VALID_TFRECORDS]\n",
    "\n",
    "# # Load features from disk\n",
    "# import glob\n",
    "# import tensorflow as tf\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# TRAIN_TFRECORDS = glob.glob('/mnt/d/drums/train*.tfrecords')\n",
    "# VALID_TFRECORDS = glob.glob('/mnt/d/drums/validate*.tfrecords')\n",
    "\n",
    "feature_description = {\n",
    "    'stft': tf.io.FixedLenFeature((spec_feature_count, segment_length), tf.float32),\n",
    "    'labels': tf.io.FixedLenFeature((output_classes, segment_length), tf.float32),\n",
    "}\n",
    "\n",
    "def _parse_feature(example):\n",
    "    parsed = tf.io.parse_single_example(example, feature_description)\n",
    "    # TODO: transpose when writing instead\n",
    "    return tf.expand_dims(tf.transpose(parsed['stft']), axis=-1), tf.transpose(parsed['labels'])\n",
    "\n",
    "def load_dataset(filename):\n",
    "    dataset_options = tf.data.Options()\n",
    "    dataset_options.experimental_deterministic = False\n",
    "    dataset_options.threading.private_threadpool_size = 16\n",
    "    dataset = tf.data.TFRecordDataset(filename, num_parallel_reads=8)\n",
    "    dataset = dataset.with_options(dataset_options)\n",
    "    dataset = dataset.map(_parse_feature, num_parallel_calls=8)\n",
    "    dataset = dataset.shuffle(512)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(2)\n",
    "    return dataset\n",
    "\n",
    "parsed_train = load_dataset(TRAIN_TFRECORDS)\n",
    "parsed_valid = load_dataset(VALID_TFRECORDS)\n",
    "\n",
    "for feature_batch, label_batch in parsed_train.take(1):\n",
    "    print(feature_batch.shape)\n",
    "    for n in range(1):\n",
    "        print(feature_batch[n].shape)\n",
    "        print(label_batch[n].shape)\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.imshow(tf.transpose(tf.squeeze(feature_batch[n], axis=-1)), interpolation='nearest', aspect='auto')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plot_labels(tf.transpose(label_batch[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, mixed_precision, Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, TimeDistributed, Dense, Activation, Conv2D, BatchNormalization, Reshape, Flatten, Input, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from IPython.display import clear_output\n",
    "\n",
    "cnn_layers = 4\n",
    "cnn_filters = 32\n",
    "cnn_dropout = 0.3\n",
    "\n",
    "lstm_units = 64\n",
    "lstm_layers = 3\n",
    "lstm_dropout = 0.1\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "inputs = Input(shape=(segment_length, spec_feature_count, 1))\n",
    "\n",
    "cnn = inputs\n",
    "for i in range(cnn_layers):\n",
    "    cnn = Conv2D(cnn_filters, (3, 3), activation='relu', padding='same', strides=1)(cnn)\n",
    "    cnn = BatchNormalization()(cnn)\n",
    "    cnn = Conv2D(cnn_filters, (3, 3), activation='relu', padding='same', strides=1)(cnn)\n",
    "    cnn = BatchNormalization()(cnn)\n",
    "    cnn = MaxPool2D(pool_size=(1, 3))(cnn)\n",
    "    cnn = Dropout(cnn_dropout)(cnn)\n",
    "    \n",
    "cnn = Reshape((segment_length, -1))(cnn)\n",
    "\n",
    "lstm = Bidirectional(LSTM(units=lstm_units, input_shape=(segment_length, -1, -1), return_sequences=True))(cnn)\n",
    "lstm = Dropout(lstm_dropout)(lstm)\n",
    "for i in range(lstm_layers - 1):\n",
    "    lstm = Bidirectional(LSTM(units=lstm_units, return_sequences=True, activation='tanh'))(lstm)\n",
    "    lstm = Dropout(lstm_dropout)(lstm)\n",
    "# lstm = TimeDistributed(Dense(spec_feature_count))(lstm)\n",
    "lstm = TimeDistributed(Dense(output_classes))(lstm)\n",
    "output = Activation('sigmoid', dtype='float32')(lstm)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['binary_crossentropy'])\n",
    "\n",
    "plot_losses = PlotLosses()\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=1, mode='auto', restore_best_weights=True)\n",
    "save = model.fit(parsed_train, batch_size=batch_size, epochs=num_epochs, validation_data=(parsed_valid), callbacks=[plot_losses, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FILE = '/mnt/d/drums/e-gmd-v1.0.0/drummer4/session1/1_rock_87_beat_4-4_1.wav'\n",
    "\n",
    "def get_onsets(filepath):\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    batches = []\n",
    "\n",
    "    def handle_slices(stft_slice, labels_slice):\n",
    "        batches.append(tf.transpose(stft_slice))\n",
    "        all_labels.append(tf.transpose(labels_slice))\n",
    "\n",
    "    process_file(filepath, handle_slices)\n",
    "    \n",
    "    predictions = model.predict(np.array(batches))\n",
    "    all_predictions = np.concatenate(predictions)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    plt.figure(figsize=(40, 10))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plot_labels(tf.transpose(all_predictions[:5000]))\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plot_labels(tf.transpose(all_labels[:5000]))\n",
    "\n",
    "get_onsets(TEST_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "23df13593d8331a82b542815a678123aa6c83e1e6e8061b22106eb2b5f0987e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
